# AI Provider Configuration
[ai]
    # AI provider to use: 'groq' (FASTEST, FREE), 'openai', 'gemini', or 'deepseek'
    provider = "deepseek"
    
    # Maximum tokens per API request (applies to all LLM providers)
    maxTokens = 8000
    
    # Temperature for AI responses (0.0-2.0, lower is more deterministic)
    temperature = 0.7

# OpenAI API Configuration
[openai]
    # Your OpenAI API key
    # Get your API key from: https://platform.openai.com/api-keys
    apiKey = "your-openai-api-key-here"
    
    # OpenAI model to use (gpt-3.5-turbo, gpt-4, gpt-4-turbo-preview)
    model = "gpt-3.5-turbo"

# DeepSeek API Configuration
[deepseek]
    # Your DeepSeek API key
    # Get your API key from: https://platform.deepseek.com/api_keys
    apiKey = "your-deepseek-api-key-here"
    
    # DeepSeek model to use (deepseek-chat, deepseek-reasoner)
    model = "deepseek-chat"

# Steve Behavior Configuration
[behavior]
    # Ticks between action checks (20 ticks = 1 second)
    actionTickDelay = 20
    
    # Allow Steves to respond in chat
    enableChatResponses = true
    
    # Maximum number of Steves that can be active simultaneously
    maxActiveSteves = 10
