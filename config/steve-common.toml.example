# AI Provider Configuration
[ai]
    # AI provider to use: 'groq' (FASTEST, FREE), 'openai', 'gemini', or 'deepseek'
    provider = "groq"
    
    # Maximum tokens per API request (applies to all LLM providers)
    maxTokens = 8000
    
    # Temperature for AI responses (0.0-2.0, lower is more deterministic)
    temperature = 0.7

# OpenAI API Configuration
[openai]
    # Your OpenAI API key
    # Get your API key from: https://platform.openai.com/api-keys
    apiKey = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # OpenAI model to use (gpt-5.2, gpt-5.2-codex, gpt-5-mini-2025-08-07, gpt-5-nano-2025-08-07)
    model = "gpt-5-mini-2025-08-07"

# DeepSeek API Configuration
[deepseek]
    # Your DeepSeek API key
    # Get your API key from: https://platform.deepseek.com/api_keys
    apiKey = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # DeepSeek model to use (deepseek-chat, deepseek-reasoner)
    model = "deepseek-chat"

# Groq API Configuration (FASTEST, FREE tier available)
[groq]
    # Your Groq API key
    # Get your API key from: https://console.groq.com/keys
    apiKey = "gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # Groq model to use (llama-3.1-8b-instant, llama-3.1-70b-versatile, mixtral-8x7b-32768)
    model = "llama-3.1-8b-instant"

# Google Gemini API Configuration
[gemini]
    # Your Gemini API key
    # Get your API key from: https://aistudio.google.com/apikey
    apiKey = "AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # Gemini model to use (gemini-3-pro-preview, gemini-3-flash-preview, gemini-flash-lite-latest)
    model = "gemini-3-flash-preview"

# Steve Behavior Configuration
[behavior]
    # Ticks between action checks (20 ticks = 1 second)
    actionTickDelay = 20
    
    # Allow Steves to respond in chat
    enableChatResponses = true
    
    # Maximum number of Steves that can be active simultaneously
    maxActiveSteves = 10
