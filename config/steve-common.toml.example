# AI Provider Configuration
[ai]
    # AI provider to use: 'longcat', 'iflow', 'deepseek', 'openai', 'gemini', or 'groq'
    provider = "longcat"
    
    # Maximum tokens per API request (applies to all LLM providers)
    maxTokens = 8000
    
    # Temperature for AI responses (0.0-2.0, lower is more deterministic)
    temperature = 0.7

# LongCat API Configuration
[longcat]
    # Your LongCat API key
    # Get your API key from: https://longcat.chat/platform/api_keys
    apiKey = "ak_xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # LongCat model to use (LongCat-Flash-Chat, LongCat-Flash-Thinking, LongCat-Flash-Thinking-2601)
    model = "LongCat-Flash-Thinking-2601"
    
# iFlow API Configuration
[iflow]
    # Your iFlow API key (get from: https://platform.iflow.cn/profile?tab=apiKey)
    apiKey = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # iFlow model to use (glm-4.6, kimi-k2, qwen3-coder-plus, qwen3-max, qwen3-vl-plus, deepseek-v3.2, tstars2.0, iflow-rome-30ba3b)
    model = "glm-4.6"

# DeepSeek API Configuration
[deepseek]
    # Your DeepSeek API key
    # Get your API key from: https://platform.deepseek.com/api_keys
    apiKey = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # DeepSeek model to use (deepseek-chat, deepseek-reasoner)
    model = "deepseek-chat"

# OpenAI API Configuration
[openai]
    # Your OpenAI API key
    # Get your API key from: https://platform.openai.com/api-keys
    apiKey = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # OpenAI model to use (gpt-5.2, gpt-5.2-codex, gpt-5-mini-2025-08-07, gpt-5-nano-2025-08-07)
    model = "gpt-5-mini-2025-08-07"

# Google Gemini API Configuration
[gemini]
    # Your Gemini API key
    # Get your API key from: https://aistudio.google.com/apikey
    apiKey = "AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # Gemini model to use (gemini-3-pro-preview, gemini-3-flash-preview, gemini-flash-lite-latest)
    model = "gemini-3-flash-preview"

# Groq API Configuration (FASTEST, FREE tier available)
[groq]
    # Your Groq API key
    # Get your API key from: https://console.groq.com/keys
    apiKey = "gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    
    # Groq model to use (llama-3.1-8b-instant, llama-3.1-70b-versatile, mixtral-8x7b-32768)
    model = "llama-3.1-8b-instant"

# Steve Behavior Configuration
[behavior]
    # Ticks between action checks (20 ticks = 1 second)
    actionTickDelay = 20
    
    # Allow Steves to respond in chat
    enableChatResponses = true
    
    # Maximum number of Steves that can be active simultaneously
    maxActiveSteves = 10
